
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>megengine.functional.nn &#8212; MegEngine 1.2.0 文档</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.57d3cd9fdfd1e83932aa4eb4774f9fb9.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/custom.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.109f8ec7af5a9d176fcd.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/translations.js"></script>
    <script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">


    
      
      <a class="navbar-brand" href="../../../index.html">
        <img src="../../../_static/logo.png" class="logo" alt="logo">
      </a>
      
    

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-menu" aria-controls="navbar-menu" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    
    <div id="navbar-menu" class="col-lg-9 collapse navbar-collapse">
      <ul id="navbar-main-elements" class="navbar-nav mr-auto">
        <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../getting-started/index.html">
  新手入门
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../user-guide/index.html">
  用户指南
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../reference/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../developmet/index.html">
  开发者指南
 </a>
</li>

        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://discuss.megengine.org.cn/">论坛<i class="fas fa-external-link-alt"></i></a>
        </li>
        
        <li class="nav-item">
            <a class="nav-link nav-external" href="https://megengine.org.cn/">官网<i class="fas fa-external-link-alt"></i></a>
        </li>
        
      </ul>

      <form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="输入搜索文本..." aria-label="输入搜索文本..." autocomplete="off" >
</form>
      <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/MegEngine/MegEngine" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>

      <ul class="navbar-nav">
        <li class="version_switcher nav-item dropdown"><script type="text/javascript">
    (function () {

        // TODO: Handle with api.json file to get the meta-data.

        // Select versions that could be switched by user
        var all_versions = {
            'latest': 'v1.2.0',
            'v1.1': 'v1.1.0',
            'v1.0': 'v1.0.0',
        };

        function change_version(url, new_version) {
            var version_regex = /\/(latest|(v\d+\.\d+.\d+))\//;
            return url.replace(version_regex, '/' + new_version + '/');
        }

        function on_switch() {
            var selected = $(this).children('option:selected').attr('value');

            // original url
            var url = window.location.href;
            // changed url
            var new_url = change_version(url, selected);

            if (new_url != url) {
                // check beforehand if url exists, otherwise redirect to the version's start page
                $.ajax({
                    url: new_url,
                    success: function () {
                        window.location.href = new_url;
                    },
                    error: function () {
                        window.location.href = "https://pydata-sphinx-theme.readthedocs.io/en/" + selected;
                    }
                });
            }
        }

        $(document).ready(function () {
            // var version = DOCUMENTATION_OPTIONS.VERSION;
            // Take the first 2 parts of the release (e.g. "3.4.5" -> "3.4")
            // version = version.split('.').slice(0, 2).join('.');

            // fill the current version in the dropdown
            document.getElementById("version-dropdown").innerText = 'latest';

            const getVersionLink = () => {
                return Object.keys(all_versions).map(key => `<button class="dropdown-item">${key}</button>`)
            }
            // fill the version menu
            document.getElementById("version-menu").innerHTML = getVersionLink().join('');

            // bind the changes to this menu to trigger the switching function
            // TODO: Change this to use the dropdown button's on_select() callback function
            $('.version-dropdown select').bind('change', on_switch);
        });
    })();

</script>

<button id="version-dropdown" class="btn btn-secondary btn-sm dropdown-toggle" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
    <!-- placeholder for javascript filling above -->
</button>
<div id="version-menu" class="dropdown-menu" style="min-width: 6rem;">
    <!-- placeholder for javascript filling above -->
</div> 
        </li>
      </ul>
    </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
      
    </ul>
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
              

<nav id="bd-toc-nav">
    
</nav>


              
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>megengine.functional.nn 源代码</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="c1"># MegEngine is Licensed under the Apache License, Version 2.0 (the &quot;License&quot;)</span>
<span class="c1">#</span>
<span class="c1"># Copyright (c) 2014-2020 Megvii Inc. All rights reserved.</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing,</span>
<span class="c1"># software distributed under the License is distributed on an</span>
<span class="c1"># &quot;AS IS&quot; BASIS, WITHOUT ARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># pylint: disable=too-many-lines</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">..core._imperative_rt</span> <span class="kn">import</span> <span class="n">CompNode</span>
<span class="kn">from</span> <span class="nn">..core._imperative_rt.core2</span> <span class="kn">import</span> <span class="n">apply</span>
<span class="kn">from</span> <span class="nn">..core._trace_option</span> <span class="kn">import</span> <span class="n">use_symbolic_shape</span>
<span class="kn">from</span> <span class="nn">..core.ops</span> <span class="kn">import</span> <span class="n">builtin</span>
<span class="kn">from</span> <span class="nn">..core.ops.builtin</span> <span class="kn">import</span> <span class="n">BatchNorm</span>
<span class="kn">from</span> <span class="nn">..core.ops.special</span> <span class="kn">import</span> <span class="n">Const</span>
<span class="kn">from</span> <span class="nn">..core.tensor</span> <span class="kn">import</span> <span class="n">megbrain_graph</span><span class="p">,</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">..core.tensor.utils</span> <span class="kn">import</span> <span class="n">astensor1d</span><span class="p">,</span> <span class="n">setscalar</span>
<span class="kn">from</span> <span class="nn">..distributed</span> <span class="kn">import</span> <span class="n">WORLD</span><span class="p">,</span> <span class="n">is_distributed</span>
<span class="kn">from</span> <span class="nn">..jit.tracing</span> <span class="kn">import</span> <span class="n">is_tracing</span>
<span class="kn">from</span> <span class="nn">..random</span> <span class="kn">import</span> <span class="n">uniform</span>
<span class="kn">from</span> <span class="nn">..tensor</span> <span class="kn">import</span> <span class="n">Tensor</span>
<span class="kn">from</span> <span class="nn">.debug_param</span> <span class="kn">import</span> <span class="n">get_conv_execution_strategy</span>
<span class="kn">from</span> <span class="nn">.distributed</span> <span class="kn">import</span> <span class="n">all_reduce_sum</span>
<span class="kn">from</span> <span class="nn">.elemwise</span> <span class="kn">import</span> <span class="n">exp</span><span class="p">,</span> <span class="n">floor</span><span class="p">,</span> <span class="n">log</span><span class="p">,</span> <span class="n">log1p</span><span class="p">,</span> <span class="n">maximum</span><span class="p">,</span> <span class="n">minimum</span><span class="p">,</span> <span class="n">relu</span>
<span class="kn">from</span> <span class="nn">.math</span> <span class="kn">import</span> <span class="n">argsort</span><span class="p">,</span> <span class="nb">max</span><span class="p">,</span> <span class="n">prod</span><span class="p">,</span> <span class="nb">sum</span>
<span class="kn">from</span> <span class="nn">.tensor</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">broadcast_to</span><span class="p">,</span>
    <span class="n">concat</span><span class="p">,</span>
    <span class="n">expand_dims</span><span class="p">,</span>
    <span class="n">full</span><span class="p">,</span>
    <span class="n">ones</span><span class="p">,</span>
    <span class="n">reshape</span><span class="p">,</span>
    <span class="n">squeeze</span><span class="p">,</span>
    <span class="n">zeros</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">.types</span> <span class="kn">import</span> <span class="n">_pair</span><span class="p">,</span> <span class="n">_pair_nonzero</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;adaptive_avg_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;adaptive_max_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;avg_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;batch_norm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv_transpose2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dot&quot;</span><span class="p">,</span>
    <span class="s2">&quot;dropout&quot;</span><span class="p">,</span>
    <span class="s2">&quot;indexing_one_hot&quot;</span><span class="p">,</span>
    <span class="s2">&quot;leaky_relu&quot;</span><span class="p">,</span>
    <span class="s2">&quot;local_conv2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;logsigmoid&quot;</span><span class="p">,</span>
    <span class="s2">&quot;logsumexp&quot;</span><span class="p">,</span>
    <span class="s2">&quot;logsoftmax&quot;</span><span class="p">,</span>
    <span class="s2">&quot;matmul&quot;</span><span class="p">,</span>
    <span class="s2">&quot;max_pool2d&quot;</span><span class="p">,</span>
    <span class="s2">&quot;one_hot&quot;</span><span class="p">,</span>
    <span class="s2">&quot;prelu&quot;</span><span class="p">,</span>
    <span class="s2">&quot;remap&quot;</span><span class="p">,</span>
    <span class="s2">&quot;softmax&quot;</span><span class="p">,</span>
    <span class="s2">&quot;softplus&quot;</span><span class="p">,</span>
    <span class="s2">&quot;svd&quot;</span><span class="p">,</span>
    <span class="s2">&quot;warp_perspective&quot;</span><span class="p">,</span>
    <span class="s2">&quot;conv1d&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="k">def</span> <span class="nf">expand_hw</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># NOTE: &gt;1d array is accepted, as long as 1 &lt;= size &lt;= 2</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">]</span>
    <span class="k">except</span> <span class="p">(</span><span class="ne">TypeError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">):</span>
        <span class="k">pass</span>
    <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span>
    <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>


<div class="viewcode-block" id="linear"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.linear.html#megengine.functional.nn.linear">[文档]</a><span class="k">def</span> <span class="nf">linear</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a linear transformation to the input tensor.</span>

<span class="sd">    Refer to :class:`~.module.linear.Linear` for more information.</span>

<span class="sd">    :param inp: input tensor with shape `(N, in_features)`.</span>
<span class="sd">    :param weight: weight with shape `(out_features, in_features)`.</span>
<span class="sd">    :param bias: bias with shape `(out_features,)`.</span>
<span class="sd">        Default: None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="conv2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.conv2d.html#megengine.functional.nn.conv2d">[文档]</a><span class="k">def</span> <span class="nf">conv2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    2D convolution operation.</span>

<span class="sd">    Refer to :class:`~.Conv2d` for more information.</span>

<span class="sd">    :param inp: feature map of the convolution operation.</span>
<span class="sd">    :param weight: convolution kernel.</span>
<span class="sd">    :param bias: bias added to the result of convolution (if given).</span>
<span class="sd">    :param stride: stride of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param padding: size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: dilation of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups into which the input and output channels are divided, so as to perform a ``grouped convolution``. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by ``groups``,</span>
<span class="sd">        and the shape of weight should be `(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)`.</span>
<span class="sd">    :type conv_mode: string or :class:`Convolution.Mode`</span>
<span class="sd">    :param conv_mode: supports &quot;CROSS_CORRELATION&quot;. Default:</span>
<span class="sd">        &quot;CROSS_CORRELATION&quot;</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: when set to &quot;DEFAULT&quot;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &quot;FLOAT32&quot;,</span>
<span class="sd">        &quot;Float32&quot; would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">Sparse</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Convolution</span><span class="o">.</span><span class="n">Sparse</span>
    <span class="n">sparse_type</span> <span class="o">=</span> <span class="s2">&quot;DENSE&quot;</span> <span class="k">if</span> <span class="n">groups</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;GROUP&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Convolution</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_conv_execution_strategy</span><span class="p">(),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="n">sparse_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="conv_transpose2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.conv_transpose2d.html#megengine.functional.nn.conv_transpose2d">[文档]</a><span class="k">def</span> <span class="nf">conv_transpose2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    2D transposed convolution operation.</span>

<span class="sd">    Refer to :class:`~.ConvTranspose2d` for more information.</span>

<span class="sd">    :param inp: feature map of the convolution operation.</span>
<span class="sd">    :param weight: convolution kernel.</span>
<span class="sd">    :param bias: bias added to the result of convolution (if given).</span>
<span class="sd">    :param stride: stride of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param padding: size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: dilation of the 2D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups into which the input and output channels are divided, so as to perform a ``grouped convolution``. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by groups,</span>
<span class="sd">        and the shape of weight should be `(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)`. Default: 1</span>
<span class="sd">    :type conv_mode: string or :class:`Convolution.Mode`</span>
<span class="sd">    :param conv_mode: supports &quot;CROSS_CORRELATION&quot;. Default:</span>
<span class="sd">        &quot;CROSS_CORRELATION&quot;</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: when set to &quot;DEFAULT&quot;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &quot;FLOAT32&quot;,</span>
<span class="sd">        &quot;Float32&quot; would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>

    <span class="k">if</span> <span class="n">groups</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;TODO&quot;</span><span class="p">)</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">ConvolutionBackwardData</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_conv_execution_strategy</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="n">weight</span><span class="p">,</span> <span class="n">inp</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="local_conv2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.local_conv2d.html#megengine.functional.nn.local_conv2d">[文档]</a><span class="k">def</span> <span class="nf">local_conv2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Applies spatial 2D convolution over an groupped channeled image with untied kernels.&quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>

    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">pad_h</span><span class="p">,</span> <span class="n">pad_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
    <span class="n">dilate_h</span><span class="p">,</span> <span class="n">dilate_w</span> <span class="o">=</span> <span class="n">expand_hw</span><span class="p">(</span><span class="n">dilation</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">GroupLocal</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">pad_w</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="n">dilate_w</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="s2">&quot;DENSE&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="max_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.max_pool2d.html#megengine.functional.nn.max_pool2d">[文档]</a><span class="k">def</span> <span class="nf">max_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D max pooling over an input tensor.</span>

<span class="sd">    Refer to :class:`~.MaxPool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param kernel_size: size of the window.</span>
<span class="sd">    :param stride: stride of the window. If not provided, its value is set to kernel_size.</span>
<span class="sd">        Default: None</span>
<span class="sd">    :param padding: implicit zero padding added on both sides. Default: 0</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="n">window_h</span><span class="p">,</span> <span class="n">window_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">padding_h</span><span class="p">,</span> <span class="n">padding_w</span> <span class="o">=</span> <span class="n">_pair</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Pooling</span><span class="p">(</span>
        <span class="n">window_h</span><span class="o">=</span><span class="n">window_h</span><span class="p">,</span>
        <span class="n">window_w</span><span class="o">=</span><span class="n">window_w</span><span class="p">,</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">padding_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">padding_w</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;MAX&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="avg_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.avg_pool2d.html#megengine.functional.nn.avg_pool2d">[文档]</a><span class="k">def</span> <span class="nf">avg_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">kernel_size</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span>
    <span class="n">stride</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;AVERAGE_COUNT_EXCLUDE_PADDING&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies 2D average pooling over an input tensor.</span>

<span class="sd">    Refer to :class:`~.AvgPool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param kernel_size: size of the window.</span>
<span class="sd">    :param stride: stride of the window. If not provided, its value is set to ``kernel_size``.</span>
<span class="sd">        Default: None</span>
<span class="sd">    :param padding: implicit zero padding added on both sides. Default: 0</span>
<span class="sd">    :param mode: whether to count padding values. Default: &quot;AVERAGE_COUNT_EXCLUDE_PADDING&quot;</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">stride</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">stride</span> <span class="o">=</span> <span class="n">kernel_size</span>
    <span class="n">window_h</span><span class="p">,</span> <span class="n">window_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">kernel_size</span><span class="p">)</span>
    <span class="n">stride_h</span><span class="p">,</span> <span class="n">stride_w</span> <span class="o">=</span> <span class="n">_pair_nonzero</span><span class="p">(</span><span class="n">stride</span><span class="p">)</span>
    <span class="n">padding_h</span><span class="p">,</span> <span class="n">padding_w</span> <span class="o">=</span> <span class="n">_pair</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Pooling</span><span class="p">(</span>
        <span class="n">window_h</span><span class="o">=</span><span class="n">window_h</span><span class="p">,</span>
        <span class="n">window_w</span><span class="o">=</span><span class="n">window_w</span><span class="p">,</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="n">stride_w</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">padding_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="n">padding_w</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="adaptive_max_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.adaptive_max_pool2d.html#megengine.functional.nn.adaptive_max_pool2d">[文档]</a><span class="k">def</span> <span class="nf">adaptive_max_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">oshp</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D max adaptive pooling over an input.</span>

<span class="sd">    Refer to :class:`~.MaxAdaptivePool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param oshp: `(OH, OW)` size of the output shape.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">megbrain_graph</span><span class="o">.</span><span class="n">VarNode</span><span class="p">)),</span> <span class="s2">&quot;inp must be Tensor type&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">oshp</span> <span class="o">=</span> <span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">AdaptivePooling</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;MAX&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,)</span>
    <span class="n">oshp</span> <span class="o">=</span> <span class="n">astensor1d</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="adaptive_avg_pool2d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.adaptive_avg_pool2d.html#megengine.functional.nn.adaptive_avg_pool2d">[文档]</a><span class="k">def</span> <span class="nf">adaptive_avg_pool2d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">oshp</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D average adaptive pooling over an input.</span>

<span class="sd">    Refer to :class:`~.AvgAdaptivePool2d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param oshp: `(OH, OW)` size of the output shape.</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">megbrain_graph</span><span class="o">.</span><span class="n">VarNode</span><span class="p">)),</span> <span class="s2">&quot;inp must be Tensor type&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">oshp</span> <span class="o">=</span> <span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">AdaptivePooling</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;AVERAGE&quot;</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,)</span>
    <span class="n">oshp</span> <span class="o">=</span> <span class="n">astensor1d</span><span class="p">(</span><span class="n">oshp</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">oshp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="prelu"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.prelu.html#megengine.functional.nn.prelu">[文档]</a><span class="k">def</span> <span class="nf">prelu</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise PReLU function.</span>

<span class="sd">    Refer to :class:`~.PReLU` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">maximum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">minimum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="leaky_relu"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.leaky_relu.html#megengine.functional.nn.leaky_relu">[文档]</a><span class="k">def</span> <span class="nf">leaky_relu</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">negative_slope</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise leaky_relu function</span>

<span class="sd">    Refer to :class:`~.LeakyReLU` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">maximum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="n">negative_slope</span> <span class="o">*</span> <span class="n">minimum</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span></div>


<div class="viewcode-block" id="softplus"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.softplus.html#megengine.functional.nn.softplus">[文档]</a><span class="k">def</span> <span class="nf">softplus</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise function:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{softplus}(x) = \log(1 + \exp(x))</span>

<span class="sd">    softplus is a smooth approximation to the ReLU function and can be used</span>
<span class="sd">    to constrain the output to be always positive.</span>
<span class="sd">    For numerical stability the implementation follows this transformation:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{softplus}(x) = \log(1 + \exp(x))</span>
<span class="sd">                           = \log(1 + \exp(-\text{abs}(x))) + \max(x, 0)</span>
<span class="sd">                           = \log1p(\exp(-\text{abs}(x))) + \text{relu}(x)</span>

<span class="sd">    :param inp: input tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-3, 3, dtype=np.float32))</span>
<span class="sd">        y = F.softplus(x)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [0.0486 0.1269 0.3133 0.6931 1.3133 2.1269]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">log1p</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="nb">abs</span><span class="p">(</span><span class="n">inp</span><span class="p">)))</span> <span class="o">+</span> <span class="n">relu</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span></div>


<div class="viewcode-block" id="logsoftmax"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.logsoftmax.html#megengine.functional.nn.logsoftmax">[文档]</a><span class="k">def</span> <span class="nf">logsoftmax</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the :math:`\log(\text{softmax}(x))` function to an n-dimensional</span>
<span class="sd">    input tensor. The :math:`\text{logsoftmax}(x)` formulation can be simplified as:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{logsoftmax}(x_{i}) = \log(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} )</span>

<span class="sd">    For numerical stability the implementation follows this transformation:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{logsoftmax}(x)</span>
<span class="sd">        = \log (\frac{\exp (x)}{\sum_{i}(\exp (x_{i}))})</span>
<span class="sd">        = x - \log (\sum_{i}(\exp (x_{i})))</span>
<span class="sd">        = x - \text{logsumexp}(x)</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param axis: axis along which :math:`\text{logsoftmax}(x)` will be applied.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32)).reshape(2,5)</span>
<span class="sd">        y = F.logsoftmax(x, axis=1)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[-4.4519 -3.4519 -2.4519 -1.4519 -0.4519]</span>
<span class="sd">         [-4.4519 -3.4519 -2.4519 -1.4519 -0.4519]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">inp</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="logsigmoid"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.logsigmoid.html#megengine.functional.nn.logsigmoid">[文档]</a><span class="k">def</span> <span class="nf">logsigmoid</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the element-wise function:</span>

<span class="sd">    .. math::</span>
<span class="sd">        \text{logsigmoid}(x) = \log(\frac{ 1 }{ 1 + \exp(-x)})</span>
<span class="sd">        = \log(1/(1 + \exp(-x)))</span>
<span class="sd">        = - \log(1 + \exp(-x))</span>
<span class="sd">        = - \text{softplus}(-x)</span>

<span class="sd">    :param inp: input tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32))</span>
<span class="sd">        y = F.logsigmoid(x)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [-5.0067 -4.0182 -3.0486 -2.1269 -1.3133 -0.6931 -0.3133 -0.1269 -0.0486</span>
<span class="sd">         -0.0181]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">softplus</span><span class="p">(</span><span class="o">-</span><span class="n">inp</span><span class="p">)</span></div>


<div class="viewcode-block" id="logsumexp"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.logsumexp.html#megengine.functional.nn.logsumexp">[文档]</a><span class="k">def</span> <span class="nf">logsumexp</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="n">keepdims</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculates the logarithm of the inputs&#39; exponential sum along the given :attr:`axis`.</span>

<span class="sd">    .. math::</span>

<span class="sd">        \text{logsumexp}(x)= \log \sum_{j=1}^{n} \exp \left(x_{j}\right)</span>

<span class="sd">    For numerical stability, the implementation follows this transformation:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \text{logsumexp}(x)= \log \sum_{j=1}^{n} \exp \left(x_{j}\right)</span>
<span class="sd">        = \text{logsumexp}(x)=b+\log \sum_{j=1}^{n} \exp \left(x_{j}-b\right)</span>

<span class="sd">    where</span>

<span class="sd">    .. math::</span>
<span class="sd">        b = \max(x_j)</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param axis: axis over which the sum is taken. It could be single axis or list of axes.</span>
<span class="sd">    :param keepdims: whether to retain :attr:`axis` or not for the output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32)).reshape(2,5)</span>
<span class="sd">        y = F.logsumexp(x, axis=1, keepdims=False)</span>
<span class="sd">        print(y.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [-0.5481  4.4519]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_value</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">keepdims</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">max_value</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">inp</span> <span class="o">-</span> <span class="n">max_value</span><span class="p">),</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">max_value</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> <span class="n">log</span><span class="p">(</span>
            <span class="nb">sum</span><span class="p">(</span><span class="n">exp</span><span class="p">(</span><span class="n">inp</span> <span class="o">-</span> <span class="n">max_value</span><span class="p">),</span> <span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="p">)</span>
        <span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_get_softmax_axis</span><span class="p">(</span><span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">ndim</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="mi">1</span>


<div class="viewcode-block" id="softmax"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.softmax.html#megengine.functional.nn.softmax">[文档]</a><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a :math:`\text{softmax}(x)` function. :math:`\text{softmax}(x)` is defined as:</span>

<span class="sd">    .. math::</span>
<span class="sd">            \text{softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}</span>

<span class="sd">    It is applied to all elements along axis, and rescales elements so that</span>
<span class="sd">    they stay in the range `[0, 1]` and sum to 1.</span>

<span class="sd">    See :class:`~megengine.module.activation.Softmax` for more details.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param axis: an axis along which :math:`\text{softmax}(x)` will be applied. By default,</span>
<span class="sd">        :math:`\text{softmax}(x)` will apply along the highest ranked axis.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(-5, 5, dtype=np.float32)).reshape(2,5)</span>
<span class="sd">        out = F.softmax(x)</span>
<span class="sd">        print(out.numpy().round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[0.0117 0.0317 0.0861 0.2341 0.6364]</span>
<span class="sd">         [0.0117 0.0317 0.0861 0.2341 0.6364]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">axis</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">axis</span> <span class="o">=</span> <span class="n">_get_softmax_axis</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">cached</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="n">inp</span> <span class="o">-</span> <span class="n">offset</span><span class="p">)</span>
    <span class="n">down</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">cached</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cached</span> <span class="o">/</span> <span class="n">down</span></div>


<div class="viewcode-block" id="batch_norm"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.batch_norm.html#megengine.functional.nn.batch_norm">[文档]</a><span class="k">def</span> <span class="nf">batch_norm</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">running_mean</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">running_var</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">momentum</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">inplace</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies batch normalization to the input.</span>

<span class="sd">    Refer to :class:`~.BatchNorm2d` and :class:`~.BatchNorm1d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param running_mean: tensor to store running mean.</span>
<span class="sd">    :param running_var: tensor to store running variance.</span>
<span class="sd">    :param weight: scaling tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\gamma` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param bias: bias tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\beta` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param training: a boolean value to indicate whether batch norm is performed</span>
<span class="sd">        in training mode. Default: False</span>
<span class="sd">    :param momentum: value used for the ``running_mean`` and ``running_var``</span>
<span class="sd">        computation.</span>
<span class="sd">        Default: 0.9</span>
<span class="sd">    :param eps: a value added to the denominator for numerical stability.</span>
<span class="sd">        Default: 1e-5</span>
<span class="sd">    :param inplace: whether to update ``running_mean`` and ``running_var`` inplace or return new tensors</span>
<span class="sd">        Default: True</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;batch_norm for ndim != 4&quot;</span><span class="p">)</span>

    <span class="n">C</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">make_full_if_none</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">=</span> <span class="n">Const</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)()</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">astensor1d</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">builtin</span><span class="o">.</span><span class="n">Broadcast</span><span class="p">(),</span> <span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">astensor1d</span><span class="p">(</span>
                <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span>
            <span class="p">)</span>
            <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">x</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="n">has_mean</span> <span class="o">=</span> <span class="n">running_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
    <span class="n">has_var</span> <span class="o">=</span> <span class="n">running_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">has_mean</span><span class="p">,</span> <span class="s2">&quot;running_mean must be provided in inference mode&quot;</span>
        <span class="k">assert</span> <span class="n">has_var</span><span class="p">,</span> <span class="s2">&quot;running_var must be provided in inference mode&quot;</span>

    <span class="k">if</span> <span class="n">has_mean</span> <span class="ow">and</span> <span class="n">running_mean</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>
    <span class="k">if</span> <span class="n">has_var</span> <span class="ow">and</span> <span class="n">running_var</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span>

    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span>
        <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span>
    <span class="p">)</span>

    <span class="n">weight</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">training</span><span class="p">:</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span>
            <span class="n">fwd_mode</span><span class="o">=</span><span class="n">BatchNorm</span><span class="o">.</span><span class="n">FwdMode</span><span class="o">.</span><span class="n">INFERENCE</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">param_dim</span><span class="o">=</span><span class="s2">&quot;DIM_1C11&quot;</span>
        <span class="p">)</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(</span>
            <span class="n">avg_factor</span><span class="o">=</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span> <span class="n">param_dim</span><span class="o">=</span><span class="s2">&quot;DIM_1C11&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">has_mean</span> <span class="ow">or</span> <span class="n">has_var</span><span class="p">:</span>
            <span class="n">running_mean</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">running_mean</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">running_var</span> <span class="o">=</span> <span class="n">make_full_if_none</span><span class="p">(</span><span class="n">running_var</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">new_mean</span><span class="p">,</span> <span class="n">new_var</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">inp</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                <span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">,</span> <span class="n">running_var</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_mean</span><span class="p">:</span>
                <span class="n">new_mean</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_var</span><span class="p">:</span>
                <span class="n">new_var</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">inplace</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">has_mean</span><span class="p">:</span>
                    <span class="n">running_mean</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_mean</span>
                <span class="k">if</span> <span class="n">has_var</span><span class="p">:</span>
                    <span class="n">running_var</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_var</span>

                <span class="k">return</span> <span class="n">inp</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">inp</span><span class="p">,</span> <span class="n">new_mean</span><span class="p">,</span> <span class="n">new_var</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">inp</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">inp</span></div>


<div class="viewcode-block" id="sync_batch_norm"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.sync_batch_norm.html#megengine.functional.nn.sync_batch_norm">[文档]</a><span class="k">def</span> <span class="nf">sync_batch_norm</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">running_mean</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">running_var</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">momentum</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-5</span><span class="p">,</span>
    <span class="n">eps_mode</span><span class="o">=</span><span class="s2">&quot;ADDITIVE&quot;</span><span class="p">,</span>
    <span class="n">group</span><span class="o">=</span><span class="n">WORLD</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies synchronized batch normalization to the input.</span>

<span class="sd">    Refer to :class:`~.BatchNorm2d` and :class:`~.BatchNorm1d` for more information.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param running_mean: tensor to store running mean.</span>
<span class="sd">    :param running_var: tensor to store running variance.</span>
<span class="sd">    :param weight: scaling tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\gamma` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param bias: bias tensor in the learnable affine parameters.</span>
<span class="sd">        See :math:`\beta` in :class:`~.BatchNorm2d`.</span>
<span class="sd">    :param training: a boolean value to indicate whether batch norm is performed</span>
<span class="sd">        in traning mode. Default: False</span>
<span class="sd">    :param momentum: value used for the ``running_mean`` and ``running_var``</span>
<span class="sd">        computation.</span>
<span class="sd">        Default: 0.9</span>
<span class="sd">    :param eps: a value added to the denominator for numerical stability.</span>
<span class="sd">        Default: 1e-5</span>
<span class="sd">    :return: output tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">eps_mode</span> <span class="ow">in</span> <span class="p">{</span><span class="s2">&quot;MAX&quot;</span><span class="p">,</span> <span class="s2">&quot;ADDITIVE&quot;</span><span class="p">},</span> <span class="s2">&quot;unknown eps_mode: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">eps_mode</span><span class="p">)</span>
    <span class="n">_channels</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">_ndim</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">_device</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">device</span>
    <span class="n">_dtype</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">_param_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">_channels</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="n">_ndim</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">_reduce_axis</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">_ndim</span><span class="p">)]</span>

    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">_sum_on_channel</span><span class="p">(</span><span class="n">inp</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">inp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">_reduce_axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">_ndim</span><span class="p">):</span>
            <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">reduce_size</span> <span class="o">*</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">channel_x1s</span> <span class="o">=</span> <span class="n">_sum_on_channel</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
        <span class="n">channel_x2s</span> <span class="o">=</span> <span class="n">_sum_on_channel</span><span class="p">(</span><span class="n">inp</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_distributed</span><span class="p">():</span>
            <span class="c1"># reduce all nodes&#39; data to calculate mean and variance</span>
            <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">Tensor</span><span class="p">(</span><span class="n">reduce_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">_dtype</span><span class="p">),</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">_ndim</span><span class="p">)</span>
            <span class="n">stat</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
                <span class="p">[</span><span class="n">reduce_size</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">_dtype</span><span class="p">),</span> <span class="n">channel_x1s</span><span class="p">,</span> <span class="n">channel_x2s</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">stat</span> <span class="o">=</span> <span class="n">all_reduce_sum</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">group</span><span class="p">)</span>
            <span class="n">reduce_size</span> <span class="o">=</span> <span class="n">stat</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">channel_x1s</span> <span class="o">=</span> <span class="n">stat</span><span class="p">[:,</span> <span class="mi">1</span> <span class="p">:</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">_channels</span><span class="p">]</span>
            <span class="n">channel_x2s</span> <span class="o">=</span> <span class="n">stat</span><span class="p">[:,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">_channels</span> <span class="p">:]</span>

        <span class="n">channel_mean</span> <span class="o">=</span> <span class="n">channel_x1s</span> <span class="o">/</span> <span class="n">reduce_size</span>
        <span class="n">channel_variance</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">channel_x1s</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="o">-</span><span class="n">reduce_size</span> <span class="o">*</span> <span class="n">reduce_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">channel_x2s</span> <span class="o">/</span> <span class="n">reduce_size</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">running_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">running_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="n">channel_variance</span> <span class="o">=</span> <span class="n">running_var</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>
        <span class="n">channel_mean</span> <span class="o">=</span> <span class="n">running_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>

    <span class="n">invsqrt_channel_variance</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">maximum</span><span class="p">(</span><span class="n">channel_variance</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span> <span class="k">if</span> <span class="n">eps_mode</span> <span class="o">==</span> <span class="s2">&quot;MAX&quot;</span> <span class="k">else</span> <span class="n">channel_variance</span> <span class="o">+</span> <span class="n">eps</span>
    <span class="p">)</span> <span class="o">**</span> <span class="o">-</span><span class="mf">0.5</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">_param_shape</span><span class="p">)</span>

    <span class="c1"># outvar = output * weight + bias</span>
    <span class="c1"># where output = inp * invsqrt_channel_variance + (</span>
    <span class="c1">#    -channel_mean * invsqrt_channel_variance</span>
    <span class="c1"># )</span>
    <span class="c1"># Manually expand output for gopt</span>

    <span class="k">if</span> <span class="n">weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">inv_var_wt</span> <span class="o">=</span> <span class="n">invsqrt_channel_variance</span> <span class="o">*</span> <span class="n">weight</span>
        <span class="n">neg_channel_mean</span> <span class="o">=</span> <span class="o">-</span><span class="n">channel_mean</span>
        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outvar</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">inv_var_wt</span> <span class="o">+</span> <span class="p">(</span><span class="n">neg_channel_mean</span> <span class="o">*</span> <span class="n">inv_var_wt</span> <span class="o">+</span> <span class="n">bias</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">outvar</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">inv_var_wt</span> <span class="o">+</span> <span class="n">neg_channel_mean</span> <span class="o">*</span> <span class="n">inv_var_wt</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outvar</span> <span class="o">=</span> <span class="n">inp</span> <span class="o">*</span> <span class="n">invsqrt_channel_variance</span> <span class="o">+</span> <span class="p">(</span>
            <span class="o">-</span><span class="n">channel_mean</span> <span class="o">*</span> <span class="n">invsqrt_channel_variance</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">outvar</span> <span class="o">=</span> <span class="n">outvar</span> <span class="o">+</span> <span class="n">bias</span>

    <span class="k">if</span> <span class="n">training</span> <span class="ow">and</span> <span class="n">running_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">running_mean</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">running_mean</span> <span class="o">*=</span> <span class="n">momentum</span>
        <span class="n">running_mean</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">channel_mean</span>
        <span class="n">channel_variance_unbiased</span> <span class="o">=</span> <span class="n">channel_x1s</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span>
            <span class="o">-</span><span class="n">reduce_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">reduce_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">+</span> <span class="n">channel_x2s</span> <span class="o">/</span> <span class="p">(</span><span class="n">reduce_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">running_var</span> <span class="o">*=</span> <span class="n">momentum</span>
        <span class="n">running_var</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">momentum</span><span class="p">)</span> <span class="o">*</span> <span class="n">channel_variance_unbiased</span>

    <span class="k">return</span> <span class="n">outvar</span></div>


<div class="viewcode-block" id="one_hot"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.one_hot.html#megengine.functional.nn.one_hot">[文档]</a><span class="k">def</span> <span class="nf">one_hot</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs one-hot encoding for the input tensor.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param num_classes: number of classes denotes the last dimension of the output tensor.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(1, 4, dtype=np.int32))</span>
<span class="sd">        out = F.one_hot(x, num_classes=4)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[0 1 0 0]</span>
<span class="sd">         [0 0 1 0]</span>
<span class="sd">         [0 0 0 1]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">zeros_tensor</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">num_classes</span><span class="p">],</span> <span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">ones_tensor</span> <span class="o">=</span> <span class="n">ones</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">IndexingSetOneHot</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">zeros_tensor</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">ones_tensor</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="warp_perspective"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.warp_perspective.html#megengine.functional.nn.warp_perspective">[文档]</a><span class="k">def</span> <span class="nf">warp_perspective</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">M</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">dsize</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
    <span class="n">border_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;REPLICATE&quot;</span><span class="p">,</span>
    <span class="n">border_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">interp_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies perspective transformation to batched 2D images.</span>

<span class="sd">    The input images are transformed to the output images by the transformation matrix:</span>

<span class="sd">    .. math::</span>
<span class="sd">            \text{output}(n, c, h, w) = \text{input} \left( n, c,</span>
<span class="sd">                \frac{M_{00}h + M_{01}w + M_{02}}{M_{20}h + M_{21}w + M_{22}},</span>
<span class="sd">                \frac{M_{10}h + M_{11}w + M_{12}}{M_{20}h + M_{21}w + M_{22}}</span>
<span class="sd">                \right)</span>

<span class="sd">    :param inp: input image.</span>
<span class="sd">    :param M: `(batch, 3, 3)` transformation matrix.</span>
<span class="sd">    :param dsize: `(h, w)` size of the output image.</span>
<span class="sd">    :param border_mode: pixel extrapolation method.</span>
<span class="sd">        Default: &quot;REPLICATE&quot;. Currently also support &quot;CONSTANT&quot;, &quot;REFLECT&quot;,</span>
<span class="sd">        &quot;REFLECT_101&quot;, &quot;WRAP&quot;.</span>
<span class="sd">    :param border_val: value used in case of a constant border. Default: 0</span>
<span class="sd">    :param interp_mode: interpolation methods.</span>
<span class="sd">        Default: &quot;LINEAR&quot;. Currently only support &quot;LINEAR&quot; mode.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Note:</span>

<span class="sd">    The transformation matrix is the inverse of that used by `cv2.warpPerspective`.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        inp_shape = (1, 1, 4, 4)</span>
<span class="sd">        x = tensor(np.arange(16, dtype=np.float32).reshape(inp_shape))</span>
<span class="sd">        M_shape = (1, 3, 3)</span>
<span class="sd">        # M defines a translation: dst(1, 1, h, w) = rst(1, 1, h+1, w+1)</span>
<span class="sd">        M = tensor(np.array([[1., 0., 1.],</span>
<span class="sd">                             [0., 1., 1.],</span>
<span class="sd">                             [0., 0., 1.]], dtype=np.float32).reshape(M_shape))</span>
<span class="sd">        out = F.warp_perspective(x, M, (2, 2))</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[[[ 5.  6.]</span>
<span class="sd">           [ 9. 10.]]]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">WarpPerspective</span><span class="p">(</span>
        <span class="n">imode</span><span class="o">=</span><span class="n">interp_mode</span><span class="p">,</span> <span class="n">bmode</span><span class="o">=</span><span class="n">border_mode</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span> <span class="n">border_val</span><span class="o">=</span><span class="n">border_val</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
    <span class="n">dsize</span> <span class="o">=</span> <span class="n">astensor1d</span><span class="p">(</span><span class="n">dsize</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dsize</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="remap"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.remap.html#megengine.functional.nn.remap">[文档]</a><span class="k">def</span> <span class="nf">remap</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">map_xy</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">border_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;REPLICATE&quot;</span><span class="p">,</span>
    <span class="n">scalar</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">interp_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies remap transformation to batched 2D images.</span>

<span class="sd">    The input images are transformed to the output images by the tensor map_xy.</span>
<span class="sd">    The output&#39;s H and W are same as map_xy&#39;s H and W.</span>

<span class="sd">    :param inp: input image</span>
<span class="sd">    :param map_xy: (batch, oh, ow, 2) transformation matrix</span>
<span class="sd">    :param border_mode: pixel extrapolation method.</span>
<span class="sd">        Default: &quot;REPLICATE&quot;. Currently also support &quot;CONSTANT&quot;, &quot;REFLECT&quot;,</span>
<span class="sd">        &quot;REFLECT_101&quot;, &quot;WRAP&quot;.</span>
<span class="sd">    :param scalar: value used in case of a constant border. Default: 0</span>
<span class="sd">    :param interp_mode: interpolation methods.</span>
<span class="sd">        Default: &quot;LINEAR&quot;. Currently only support &quot;LINEAR&quot; mode.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>
<span class="sd">        inp_shape = (1, 1, 4, 4)</span>
<span class="sd">        inp = tensor(np.arange(16, dtype=np.float32).reshape(inp_shape))</span>
<span class="sd">        map_xy_shape = (1, 2, 2, 2)</span>
<span class="sd">        map_xy = tensor(np.array([[[1., 0.],[0., 1.]],</span>
<span class="sd">                            [[0., 1.],[0., 1.]]],</span>
<span class="sd">                             dtype=np.float32).reshape(map_xy_shape))</span>
<span class="sd">        out = F.remap(inp, map_xy)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[[[1. 4.]</span>
<span class="sd">           [4. 4.]]]]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Remap</span><span class="p">(</span>
        <span class="n">imode</span><span class="o">=</span><span class="n">interp_mode</span><span class="p">,</span> <span class="n">border_type</span><span class="o">=</span><span class="n">border_mode</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span> <span class="n">scalar</span><span class="o">=</span><span class="n">scalar</span>
    <span class="p">)</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">megbrain_graph</span><span class="o">.</span><span class="n">VarNode</span><span class="p">)),</span> <span class="s2">&quot;inp must be Tensor type&quot;</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">map_xy</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span>
    <span class="n">inp1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">inp2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">transpose_a</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">transpose_b</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
    <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a matrix multiplication of the matrices ``inp1`` and ``inp2``.</span>

<span class="sd">    With different inputs dim, this function behaves differently:</span>

<span class="sd">    - Both 1-D tensor, simply forward to ``dot``.</span>
<span class="sd">    - Both 2-D tensor, normal matrix multiplication.</span>
<span class="sd">    - If one input tensor is 1-D, matrix vector multiplication.</span>
<span class="sd">    - If at least one tensor are 3-dimensional or &gt;3-dimensional, the other tensor should have dim &gt;= 2, the batched matrix-matrix is returned, and the tensor with smaller dimension will</span>
<span class="sd">      be broadcasted. For example:</span>
<span class="sd">        - inp1: `(n, k, m)`, inp2: `(n, m, p)`, return: `(n, k, p)`</span>
<span class="sd">        - inp1: `(n, k, m)`, inp2: `(m, p)`, return: `(n, k, p)`</span>
<span class="sd">        - inp1: `(n, j, k, m)`, inp2: `(n, j, m, p)`, return: `(n, j, k, p)`</span>

<span class="sd">    :param inp1: first matrix to be multiplied.</span>
<span class="sd">    :param inp2: second matrix to be multiplied.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        data1 = tensor(np.arange(0, 6, dtype=np.float32).reshape(2, 3))</span>
<span class="sd">        data2 = tensor(np.arange(0, 6, dtype=np.float32).reshape(3, 2))</span>
<span class="sd">        out = F.matmul(data1, data2)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[10. 13.]</span>
<span class="sd">         [28. 40.]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">remove_row</span><span class="p">,</span> <span class="n">remove_col</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span>
    <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>

    <span class="n">dim1</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">inp2</span><span class="o">.</span><span class="n">ndim</span>
    <span class="c1"># handle dim=1 cases, dot and matrix-vector multiplication</span>
    <span class="k">if</span> <span class="n">dim1</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">dim2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dot</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="c1"># the underlying matmul op requires input dims to be at least 2</span>
    <span class="k">if</span> <span class="n">dim1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">inp1</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">dim1</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">remove_row</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">dim2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">inp2</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">dim2</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">remove_col</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">batch_shape</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">shape1</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">shape2</span> <span class="o">=</span> <span class="n">inp2</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">maxdim</span> <span class="o">=</span> <span class="n">dim1</span> <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;</span> <span class="n">dim2</span> <span class="k">else</span> <span class="n">dim2</span>
    <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;=</span> <span class="mi">3</span> <span class="ow">or</span> <span class="n">dim2</span> <span class="o">&gt;=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_symbolic_shape</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape2</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="n">inp2</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp2</span><span class="p">,</span> <span class="n">shape2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&lt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape1</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">shape2</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="n">inp1</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">shape1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">maxdim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="c1"># compress inputs to 3d</span>
                <span class="p">(</span><span class="n">inp1</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                    <span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">inp1</span><span class="p">,</span> <span class="n">concat</span><span class="p">([</span><span class="n">prod</span><span class="p">(</span><span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="p">)</span>
                <span class="p">(</span><span class="n">inp2</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                    <span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">inp2</span><span class="p">,</span> <span class="n">concat</span><span class="p">([</span><span class="n">prod</span><span class="p">(</span><span class="n">shape2</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&gt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape2</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
                <span class="n">inp2</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp2</span><span class="p">,</span> <span class="n">shape2</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dim1</span> <span class="o">&lt;</span> <span class="n">dim2</span><span class="p">:</span>
                <span class="n">shape1</span> <span class="o">=</span> <span class="n">shape2</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]</span>
                <span class="n">inp1</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">shape1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">maxdim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">batch_shape</span> <span class="o">=</span> <span class="n">shape1</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
                <span class="c1"># compress inputs to 3d</span>
                <span class="n">inp1</span> <span class="o">=</span> <span class="n">inp1</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
                <span class="n">inp2</span> <span class="o">=</span> <span class="n">inp2</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">shape2</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">BatchedMatrixMul</span><span class="p">(</span>
            <span class="n">transposeA</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span>
            <span class="n">transposeB</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
            <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">MatrixMul</span><span class="p">(</span>
            <span class="n">transposeA</span><span class="o">=</span><span class="n">transpose_a</span><span class="p">,</span>
            <span class="n">transposeB</span><span class="o">=</span><span class="n">transpose_b</span><span class="p">,</span>
            <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
            <span class="nb">format</span><span class="o">=</span><span class="nb">format</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">maxdim</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">use_symbolic_shape</span><span class="p">():</span>
            <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
                <span class="n">builtin</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(),</span> <span class="n">result</span><span class="p">,</span> <span class="n">concat</span><span class="p">([</span><span class="n">batch_shape</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:]])</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_shape</span> <span class="o">+</span> <span class="n">result</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">:])</span>
    <span class="k">if</span> <span class="n">remove_row</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">remove_col</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">dot</span><span class="p">(</span><span class="n">inp1</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">inp2</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes dot-product of two vectors ``inp1`` and ``inp2``.</span>
<span class="sd">    inputs must be 1-dimensional or scalar. A scalar input is automatically broadcasted.</span>
<span class="sd">    Refer to :func:`~.matmul` for more general usage.</span>

<span class="sd">    :param inp1: first vector.</span>
<span class="sd">    :param inp2: second vector.</span>
<span class="sd">    :return: output value.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        data1 = tensor(np.arange(0, 6, dtype=np.float32))</span>
<span class="sd">        data2 = tensor(np.arange(0, 6, dtype=np.float32))</span>
<span class="sd">        out = F.dot(data1, data2)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        55.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Dot</span><span class="p">()</span>
    <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">inp1</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;=</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">inp2</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&lt;=</span> <span class="mi">1</span>
    <span class="p">),</span> <span class="s2">&quot;Input tensors for dot must be 1-dimensional or scalar&quot;</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp1</span><span class="p">,</span> <span class="n">inp2</span><span class="p">)</span>
    <span class="n">setscalar</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">svd</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the singular value decompositions of input matrix.</span>

<span class="sd">    :param inp: input matrix, must has shape `[..., M, N]`.</span>
<span class="sd">    :return: output matrices, `(U, sigma, V)`.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(0, 6, dtype=np.float32).reshape(2,3))</span>
<span class="sd">        _, y, _ = F.svd(x)</span>
<span class="sd">        print(y.numpy().round(decimals=3))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [7.348 1.   ]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">SVD</span><span class="p">(</span><span class="n">full_matrices</span><span class="o">=</span><span class="n">full_matrices</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="n">compute_uv</span><span class="p">)</span>
    <span class="n">U</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">U</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">V</span>


<div class="viewcode-block" id="interpolate"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.interpolate.html#megengine.functional.nn.interpolate">[文档]</a><span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">scale_factor</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;BILINEAR&quot;</span><span class="p">,</span>
    <span class="n">align_corners</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Down/up samples the input tensor to either the given size or with the given scale_factor. ``size`` can not coexist with ``scale_factor``.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param size: size of the output tensor. Default: None</span>
<span class="sd">    :param scale_factor: scaling factor of the output tensor. Default: None</span>
<span class="sd">    :param mode: interpolation methods, acceptable values are:</span>
<span class="sd">        &quot;BILINEAR&quot;, &quot;LINEAR&quot;. Default: &quot;BILINEAR&quot;</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.arange(1, 5, dtype=np.float32).reshape(1, 1, 2, 2))</span>
<span class="sd">        out = F.nn.interpolate(x, [4, 4], align_corners=False)</span>
<span class="sd">        print(out.numpy())</span>
<span class="sd">        out2 = F.nn.interpolate(x, scale_factor=2.)</span>
<span class="sd">        np.testing.assert_allclose(out.numpy(), out2.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [[[[1.   1.25 1.75 2.  ]</span>
<span class="sd">           [1.5  1.75 2.25 2.5 ]</span>
<span class="sd">           [2.5  2.75 3.25 3.5 ]</span>
<span class="sd">           [3.   3.25 3.75 4.  ]]]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;BILINEAR&quot;</span><span class="p">,</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;interpolate only support linear or bilinear mode&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;BILINEAR&quot;</span><span class="p">,</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">align_corners</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;align_corners option can only be set in the bilinear/linear interpolating mode&quot;</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">align_corners</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">align_corners</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
        <span class="n">inp</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">4</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;shape of input tensor must correspond to the operartion mode&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">scale_factor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;scale_factor must not be None when size is None&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">)):</span>
            <span class="n">scale_factor</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
                <span class="n">scale_factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">scale_factor</span> <span class="o">=</span> <span class="p">(</span><span class="n">scale_factor</span><span class="p">,</span> <span class="n">scale_factor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;under LINEAR mode, scale_factor can only be single value&quot;</span>
                <span class="p">)</span>

        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;shape of scale_factor must be equal to (2, )&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">scale_factor</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">scale_factor</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="nb">float</span>
        <span class="p">),</span> <span class="s2">&quot;scale_factor must be float type&quot;</span>
        <span class="n">dsize</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span>
            <span class="n">floor</span><span class="p">(</span>
                <span class="n">Tensor</span><span class="p">(</span>
                    <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">scale_factor</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">dsize</span> <span class="o">=</span> <span class="n">concat</span><span class="p">([</span><span class="n">dsize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dsize</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">scale_factor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;scale_factor must be None when size is provided&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;under LINEAR mode, size can only be single value&quot;</span><span class="p">)</span>
        <span class="n">dsize</span> <span class="o">=</span> <span class="n">size</span>

    <span class="n">oh</span><span class="p">,</span> <span class="n">ow</span> <span class="o">=</span> <span class="n">dsize</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dsize</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ih</span><span class="p">,</span> <span class="n">iw</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">align_corners</span><span class="p">:</span>
        <span class="n">hscale</span> <span class="o">=</span> <span class="p">(</span><span class="n">ih</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">oh</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">wscale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">iw</span> <span class="o">/</span> <span class="n">ow</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
            <span class="n">wscale</span> <span class="o">=</span> <span class="p">(</span><span class="n">iw</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">ow</span> <span class="o">-</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">row0</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">wscale</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">row1</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">hscale</span><span class="p">,</span>
                <span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">],</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">row0</span><span class="p">,</span> <span class="n">row1</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">hscale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">ih</span> <span class="o">/</span> <span class="n">oh</span>
        <span class="n">wscale</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">iw</span> <span class="o">/</span> <span class="n">ow</span>
        <span class="n">row0</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">wscale</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">wscale</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">],</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">row1</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">Tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">hscale</span><span class="p">,</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">hscale</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">],</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">concat</span><span class="p">(</span>
            <span class="p">[</span><span class="n">row0</span><span class="p">,</span> <span class="n">row1</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)],</span>
            <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">broadcast_to</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="n">ret</span> <span class="o">=</span> <span class="n">warp_perspective</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">dsize</span><span class="p">,</span> <span class="n">interp_mode</span><span class="o">=</span><span class="s2">&quot;LINEAR&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;LINEAR&quot;</span><span class="p">:</span>
        <span class="n">ret</span> <span class="o">=</span> <span class="n">reshape</span><span class="p">(</span><span class="n">ret</span><span class="p">,</span> <span class="n">ret</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">ret</span></div>


<div class="viewcode-block" id="dropout"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.dropout.html#megengine.functional.nn.dropout">[文档]</a><span class="k">def</span> <span class="nf">dropout</span><span class="p">(</span><span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">drop_prob</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">training</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new tensor where each of the elements are randomly set to zero</span>
<span class="sd">    with probability P = ``drop_prob``. Optionally rescale the output tensor if ``training`` is True.</span>

<span class="sd">    :param inp: input tensor.</span>
<span class="sd">    :param drop_prob: probability to drop (set to zero) a single element.</span>
<span class="sd">    :param training: the default behavior of ``dropout`` during training is to rescale the output,</span>
<span class="sd">        then it can be replaced by an :class:`~.Identity` during inference. Default: True</span>
<span class="sd">    :return: the output tensor</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = tensor(np.ones(10, dtype=np.float32))</span>
<span class="sd">        out = F.dropout(x, 1./3.)</span>
<span class="sd">        print(out.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>
<span class="sd">        :options: +SKIP</span>

<span class="sd">        [1.5 1.5 0.  1.5 1.5 1.5 1.5 1.5 1.5 1.5]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">drop_prob</span> <span class="o">&lt;</span> <span class="mi">1</span>
    <span class="n">rv</span> <span class="o">=</span> <span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">rv</span> <span class="o">&gt;</span> <span class="n">drop_prob</span>
    <span class="n">inp</span> <span class="o">*=</span> <span class="n">mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">training</span><span class="p">:</span>
        <span class="n">inp</span> <span class="o">*=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">drop_prob</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inp</span></div>


<div class="viewcode-block" id="embedding"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.embedding.html#megengine.functional.nn.embedding">[文档]</a><span class="k">def</span> <span class="nf">embedding</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">padding_idx</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">max_norm</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">norm_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies lookup table for embedding.</span>

<span class="sd">    :param inp: tensor with indices.</span>
<span class="sd">    :param weight: learnable weights which embeds from.</span>
<span class="sd">    :param padding_idx: should be set to None, not supported now.</span>
<span class="sd">    :param max_norm: should be set to None, not supported now.</span>
<span class="sd">    :param norm_type: should be set to None, not supported now.</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Refer to :class:`~.Embedding` for more information.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">padding_idx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not support padding_idx Now!&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">norm_type</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Not support weight normlization Now!&quot;</span><span class="p">)</span>

    <span class="n">dest_shp</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">weight</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">weight</span><span class="p">[</span><span class="n">inp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">dest_shp</span><span class="p">)</span></div>


<div class="viewcode-block" id="roi_pooling"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.roi_pooling.html#megengine.functional.nn.roi_pooling">[文档]</a><span class="k">def</span> <span class="nf">roi_pooling</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">rois</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">output_shape</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">],</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span>
    <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies roi pooling on input feature.</span>

<span class="sd">    :param inp: tensor that represents the input feature, `(N, C, H, W)` images.</span>
<span class="sd">    :param rois: `(K, 5)` boxes. First column is the index into N. The other 4 columns are xyxy.</span>
<span class="sd">    :param output_shape: `(height, width)` of output rois feature.</span>
<span class="sd">    :param mode: &quot;max&quot; or &quot;average&quot;, use max/average align just like max/average pooling. Default: &quot;max&quot;</span>
<span class="sd">    :param scale: scale the input boxes by this number. Default: 1.0</span>
<span class="sd">    :return: `(K, C, output_shape[0], output_shape[1])` feature of rois.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">            import numpy as np</span>
<span class="sd">            from megengine import tensor</span>
<span class="sd">            import megengine.functional as F</span>

<span class="sd">            np.random.seed(42)</span>
<span class="sd">            inp = tensor(np.random.randn(1, 1, 128, 128))</span>
<span class="sd">            rois = tensor(np.random.random((4, 5)))</span>
<span class="sd">            y = F.nn.roi_pooling(inp, rois, (2, 2))</span>
<span class="sd">            print(y.numpy()[0].round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">            [[[-0.1383 -0.1383]</span>
<span class="sd">              [-0.5035 -0.5035]]]</span>


<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;average&quot;</span><span class="p">],</span> <span class="s2">&quot;only max/average mode is supported&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">)</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">ROIPooling</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">rois</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">rois</span><span class="p">)</span>
    <span class="n">result</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span>
        <span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">rois</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">inp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="roi_align"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.roi_align.html#megengine.functional.nn.roi_align">[文档]</a><span class="k">def</span> <span class="nf">roi_align</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">rois</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">output_shape</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">],</span>
    <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;average&quot;</span><span class="p">,</span>
    <span class="n">spatial_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
    <span class="n">sample_points</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">aligned</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies roi align on input feature.</span>

<span class="sd">    :param inp: tensor that represents the input feature, shape is `(N, C, H, W)`.</span>
<span class="sd">    :param rois: `(N, 5)` boxes. First column is the box index. The other 4 columns are ``xyxy``.</span>
<span class="sd">    :param output_shape: `(height, width)` shape of output rois feature.</span>
<span class="sd">    :param mode: &quot;max&quot; or &quot;average&quot;, use max/average align just like max/average pooling. Default: &quot;average&quot;</span>
<span class="sd">    :param spatial_scale: scale the input boxes by this number. Default: 1.0</span>
<span class="sd">    :param sample_points: number of inputs samples to take for each output sample.</span>
<span class="sd">        0 to take samples densely. Default: 2</span>
<span class="sd">    :param aligned: wheather to align the input feature, with `aligned=True`,</span>
<span class="sd">        we first appropriately scale the ROI and then shift it by -0.5. Default: True</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">            import numpy as np</span>
<span class="sd">            from megengine import tensor</span>
<span class="sd">            import megengine.functional as F</span>

<span class="sd">            np.random.seed(42)</span>
<span class="sd">            inp = tensor(np.random.randn(1, 1, 128, 128))</span>
<span class="sd">            rois = tensor(np.random.random((4, 5)))</span>
<span class="sd">            y = F.nn.roi_align(inp, rois, (2, 2))</span>
<span class="sd">            print(y.numpy()[0].round(decimals=4))</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">            [[[0.175  0.175 ]</span>
<span class="sd">              [0.1359 0.1359]]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;average&quot;</span><span class="p">],</span> <span class="s2">&quot;only max/average mode is supported&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">output_shape</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">)</span>
    <span class="n">pooled_height</span><span class="p">,</span> <span class="n">pooled_width</span> <span class="o">=</span> <span class="n">output_shape</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_points</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">sample_points</span> <span class="o">=</span> <span class="p">(</span><span class="n">sample_points</span><span class="p">,</span> <span class="n">sample_points</span><span class="p">)</span>
    <span class="n">sample_height</span><span class="p">,</span> <span class="n">sample_width</span> <span class="o">=</span> <span class="n">sample_points</span>
    <span class="n">offset</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="k">if</span> <span class="n">aligned</span> <span class="k">else</span> <span class="mf">0.0</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">ROIAlign</span><span class="p">(</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">,</span>
        <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;NCHW&quot;</span><span class="p">,</span>
        <span class="n">spatial_scale</span><span class="o">=</span><span class="n">spatial_scale</span><span class="p">,</span>
        <span class="n">offset</span><span class="o">=</span><span class="n">offset</span><span class="p">,</span>
        <span class="n">pooled_height</span><span class="o">=</span><span class="n">pooled_height</span><span class="p">,</span>
        <span class="n">pooled_width</span><span class="o">=</span><span class="n">pooled_width</span><span class="p">,</span>
        <span class="n">sample_height</span><span class="o">=</span><span class="n">sample_height</span><span class="p">,</span>
        <span class="n">sample_width</span><span class="o">=</span><span class="n">sample_width</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">rois</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">rois</span><span class="p">)</span>
    <span class="n">result</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">rois</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="indexing_one_hot"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.indexing_one_hot.html#megengine.functional.nn.indexing_one_hot">[文档]</a><span class="k">def</span> <span class="nf">indexing_one_hot</span><span class="p">(</span>
    <span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    One-hot indexing for some axes.</span>

<span class="sd">    :param src: input tensor.</span>
<span class="sd">    :param index: index tensor.</span>
<span class="sd">    :param axis: axis on src for which values in index index. Default: 1</span>
<span class="sd">    :param keepdims: whether not to remove the axis in result. Default: False</span>
<span class="sd">    :return: output tensor.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import megengine.functional as F</span>
<span class="sd">        from megengine import tensor</span>

<span class="sd">        src = tensor([[1.0, 2.0]])</span>
<span class="sd">        index = tensor([0])</span>
<span class="sd">        val = F.indexing_one_hot(src, index)</span>
<span class="sd">        print(val.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [1.]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">),</span> <span class="s2">&quot;src must be of Tensor type&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">IndexingOneHot</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_single_value</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;int32&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">(</span><span class="n">result</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">keepdims</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">axis</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span></div>


<div class="viewcode-block" id="conv1d"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.conv1d.html#megengine.functional.nn.conv1d">[文档]</a><span class="k">def</span> <span class="nf">conv1d</span><span class="p">(</span>
    <span class="n">inp</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">weight</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
    <span class="n">bias</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stride</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">padding</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">dilation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">groups</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">conv_mode</span><span class="o">=</span><span class="s2">&quot;CROSS_CORRELATION&quot;</span><span class="p">,</span>
    <span class="n">compute_mode</span><span class="o">=</span><span class="s2">&quot;DEFAULT&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;1D convolution operation.</span>

<span class="sd">    Refer to :class:`~.Conv1d` for more information.</span>

<span class="sd">    :param inp: The feature map of the convolution operation</span>
<span class="sd">    :param weight: The convolution kernel</span>
<span class="sd">    :param bias: The bias added to the result of convolution (if given)</span>
<span class="sd">    :param stride: Stride of the 1D convolution operation. Default: 1</span>
<span class="sd">    :param padding: Size of the paddings added to the input on both sides of its</span>
<span class="sd">        spatial dimensions. Only zero-padding is supported. Default: 0</span>
<span class="sd">    :param dilation: Dilation of the 1D convolution operation. Default: 1</span>
<span class="sd">    :param groups: number of groups to divide input and output channels into,</span>
<span class="sd">        so as to perform a &quot;grouped convolution&quot;. When ``groups`` is not 1,</span>
<span class="sd">        ``in_channels`` and ``out_channels`` must be divisible by ``groups``,</span>
<span class="sd">        and the shape of weight should be ``(groups, out_channel // groups,</span>
<span class="sd">        in_channels // groups, height, width)``.</span>
<span class="sd">    :type conv_mode: string or :class:`mgb.opr_param_defs.Convolution.Mode`</span>
<span class="sd">    :param conv_mode: Supports &#39;CROSS_CORRELATION&#39;. Default:</span>
<span class="sd">        &#39;CROSS_CORRELATION&#39;.</span>
<span class="sd">    :type compute_mode: string or</span>
<span class="sd">        :class:`mgb.opr_param_defs.Convolution.ComputeMode`</span>
<span class="sd">    :param compute_mode: When set to &#39;DEFAULT&#39;, no special requirements will be</span>
<span class="sd">        placed on the precision of intermediate results. When set to &#39;FLOAT32&#39;,</span>
<span class="sd">        Float32 would be used for accumulator and intermediate result, but only</span>
<span class="sd">        effective when input and output are of Float16 dtype.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">assert</span> <span class="n">conv_mode</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span> <span class="ow">or</span> <span class="n">conv_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;CROSS_CORRELATION&quot;</span>
    <span class="k">assert</span> <span class="n">compute_mode</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span> <span class="ow">or</span> <span class="n">compute_mode</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;DEFAULT&quot;</span>
    <span class="k">assert</span> <span class="n">inp</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;the input dimension of conv1d should be 3&quot;</span>
    <span class="k">assert</span> <span class="n">weight</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;the weight dimension of conv1d should be 3&quot;</span>

    <span class="n">inp</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">bias</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;the bias dimension of conv1d should be 3&quot;</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">expand_dims</span><span class="p">(</span><span class="n">bias</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

    <span class="n">stride_h</span> <span class="o">=</span> <span class="n">stride</span>
    <span class="n">pad_h</span> <span class="o">=</span> <span class="n">padding</span>
    <span class="n">dilate_h</span> <span class="o">=</span> <span class="n">dilation</span>

    <span class="n">sparse_type</span> <span class="o">=</span> <span class="s2">&quot;DENSE&quot;</span> <span class="k">if</span> <span class="n">groups</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;GROUP&quot;</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">Convolution</span><span class="p">(</span>
        <span class="n">stride_h</span><span class="o">=</span><span class="n">stride_h</span><span class="p">,</span>
        <span class="n">stride_w</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">pad_h</span><span class="o">=</span><span class="n">pad_h</span><span class="p">,</span>
        <span class="n">pad_w</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">dilate_h</span><span class="o">=</span><span class="n">dilate_h</span><span class="p">,</span>
        <span class="n">dilate_w</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">strategy</span><span class="o">=</span><span class="n">get_conv_execution_strategy</span><span class="p">(),</span>
        <span class="n">mode</span><span class="o">=</span><span class="n">conv_mode</span><span class="p">,</span>
        <span class="n">compute_mode</span><span class="o">=</span><span class="n">compute_mode</span><span class="p">,</span>
        <span class="n">sparse</span><span class="o">=</span><span class="n">sparse_type</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="p">(</span><span class="n">output</span><span class="p">,)</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">inp</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">+=</span> <span class="n">bias</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">squeeze</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span></div>


<div class="viewcode-block" id="nms"><a class="viewcode-back" href="../../../reference/api/megengine.functional.nn.nms.html#megengine.functional.nn.nms">[文档]</a><span class="k">def</span> <span class="nf">nms</span><span class="p">(</span>
    <span class="n">boxes</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">iou_thresh</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">max_output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs non-maximum suppression (NMS) on the boxes according to their intersection-over-union(IoU).</span>

<span class="sd">    :param boxes: tensor of shape `(N, 4)`; the boxes to perform nms on; each box is expected to be in `(x1, y1, x2, y2)` format.</span>
<span class="sd">    :param iou_thresh: IoU threshold for overlapping.</span>
<span class="sd">    :param scores: tensor of shape `(N,)`, the score of boxes.</span>
<span class="sd">    :param max_output: the maximum number of boxes to keep; it is optional if this operator is not traced</span>
<span class="sd">        otherwise it required to be specified; if it is not specified, all boxes are kept.</span>
<span class="sd">    :return: indices of the elements that have been kept by NMS.</span>

<span class="sd">    Examples:</span>

<span class="sd">    .. testcode::</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = np.zeros((100,4))</span>
<span class="sd">        np.random.seed(42)</span>
<span class="sd">        x[:,:2] = np.random.rand(100,2)*20</span>
<span class="sd">        x[:,2:] = np.random.rand(100,2)*20 + 100</span>
<span class="sd">        scores = tensor(np.random.rand(100))</span>
<span class="sd">        inp = tensor(x)</span>
<span class="sd">        result = F.nn.nms(inp, scores, iou_thresh=0.7)</span>
<span class="sd">        print(result.numpy())</span>

<span class="sd">    Outputs:</span>

<span class="sd">    .. testoutput::</span>

<span class="sd">        [75 69]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">boxes</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>
    <span class="p">),</span> <span class="s2">&quot;the expected shape of boxes is (N, 4)&quot;</span>
    <span class="k">assert</span> <span class="n">scores</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;the expected shape of scores is (N,)&quot;</span>
    <span class="k">assert</span> <span class="p">(</span>
        <span class="n">boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">),</span> <span class="s2">&quot;number of boxes and scores are not matched&quot;</span>

    <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">scores</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">sorted_idx</span> <span class="o">=</span> <span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[</span><span class="n">sorted_idx</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">is_tracing</span><span class="p">():</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">max_output</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">max_output</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;max_output should be specified under tracing&quot;</span>

    <span class="k">if</span> <span class="n">max_output</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">max_output</span> <span class="o">=</span> <span class="n">boxes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">NMSKeep</span><span class="p">(</span><span class="n">iou_thresh</span><span class="p">,</span> <span class="n">max_output</span><span class="p">)</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">convert_inputs</span><span class="p">(</span><span class="n">boxes</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">indices</span><span class="p">,</span> <span class="n">count</span> <span class="o">=</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="o">*</span><span class="n">inp</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">][:</span> <span class="n">count</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="n">keep_inds</span> <span class="o">=</span> <span class="n">sorted_idx</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">keep_inds</span></div>


<span class="k">def</span> <span class="nf">nvof</span><span class="p">(</span><span class="n">src</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements NVIDIA Optical Flow SDK.</span>

<span class="sd">    :src shape: input tensor with shape (n, t, h, w, c4).</span>
<span class="sd">    :src dtype: uint8.</span>
<span class="sd">    :param precision: 0:NV_OF_PERF_LEVEL_SLOW 1:NV_OF_PERF_LEVEL_MEDIUM 2:NV_OF_PERF_LEVEL_FAST.</span>
<span class="sd">    :output shape: (n, t-1, h//4, w//4, c2).</span>
<span class="sd">    :output dtype: int16.</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        import numpy as np</span>
<span class="sd">        from megengine import tensor</span>
<span class="sd">        import megengine.functional as F</span>

<span class="sd">        x = np.random.random_integers(0, 255, (1,2,224,244,4)).astype(&quot;uint8&quot;)</span>
<span class="sd">        src = tensor(x)</span>
<span class="sd">        result = F.nn.nvof(src, precision=1)</span>
<span class="sd">        print(result.numpy())</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="p">(</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">megbrain_graph</span><span class="o">.</span><span class="n">VarNode</span><span class="p">)),</span> <span class="s2">&quot;src must be Tensor type&quot;</span>
    <span class="k">assert</span> <span class="n">src</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">5</span> <span class="ow">and</span> <span class="n">src</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span>

    <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

    <span class="n">op</span> <span class="o">=</span> <span class="n">builtin</span><span class="o">.</span><span class="n">NvOf</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">apply</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">src</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>


<span class="kn">from</span> <span class="nn">.loss</span> <span class="kn">import</span> <span class="o">*</span>  <span class="c1"># isort:skip</span>
<span class="kn">from</span> <span class="nn">.quantized</span> <span class="kn">import</span> <span class="n">conv_bias_activation</span>  <span class="c1"># isort:skip</span>
</pre></div>

              </div>
              
              
          </main>
          

      </div>
    </div>

    
  <script src="../../../_static/js/index.109f8ec7af5a9d176fcd.js"></script>


    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020-2021, The MegEngine Open Source Team.<br/>
        由 <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.2 创建。<br/>
    </p>
  </div>
</footer>
  </body>
</html>